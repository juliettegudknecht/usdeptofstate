# -*- coding: utf-8 -*-
"""Task5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FkIHkT1yViwkWE0xbh_MiqUOoe0DS1cI

# Task 5 - Data Formatting to CSV

We need a way in which we can store the data we gather during webscrapes into a CSV. 

## Instructions

Create a function that takes in several lists of values, creates a dataframe and saves it as a CSV. This function should...


The function should 


*   Check to make sure all inputted lists are of equal size. 
*   Take in a single string that is a **label** for the entire CSV. 
*   Take in a **list of links** that were webscraped from the bodies of text of the same index. 
*   Take in a **list of sources** of where this text came from. Academic journal name? Website name? of the bodies of text from the same index. 
*   Take in a **list of university names** of where this text came from. 
*   Take in a **lis of deperatment names** text came from the university
*   Take in a **list of titles** of the various bodies of text of the same index. 
*   Take in a **list of authors** of the various bodies of text of the same index.
*   Take in a **list of dates** of when the text was written. 
*   Take in a **list of external references** made in the text. Citations, links, etc. 
*   Take in a **list of text** that was webscraped. 
*   Take in a **list of times** and dates of when the site was webscraped. 
*   Function should log errors in a txt file with a path set in an inputted file location. Type of error + time of error should be in the log. 
*   Function should print any errors. 
*   Function should return nothing but save a CSV file into a path set in an inputted file location. 

## Technologies
*   Pandas package in Python
"""

#packages
import pandas as pd

# import logging library 
import logging

# test values
l = 'label'
links = ['link1','link2']
sources = ['source1','source2']
univs = ['univ1','univ2']
depts = ['dep1','dep2']
titles = ['title1','title2']
authors = ['author1','author2']
dates = ['date1','date2']
refs = ['ref1','ref2']
txts = ['txt1','txt2']
times = ['time1','time2']

# function that takes label, links, sources, universities, departments, titles, 
# authors, dates, references, texts and times

def build_output(l,links,sources,univs,depts,titles,authors,dates,refs,txts,times):
  try:
    baselen = len(links)
    if len(sources) != baselen:
      raise Exception("Sources is a different length than Links")
    if len(univs) != baselen:
      raise Exception("Univs is a different length than Links")
    if len(depts) != baselen:
      raise Exception("Depts is a different length than Links")
    if len(titles) != baselen:
      raise Exception("Titles is a different length than Links")
    if len(authors) != baselen:
      raise Exception("Authors is a different length than Links")
    if len(dates) != baselen:
      raise Exception("Dates is a different length than Links")
    if len(refs) != baselen:
      raise Exception("Refs is a different length than Links")
    if len(txts) != baselen:
      raise Exception("Txts is a different length than Links")
    if len(times) != baselen:
      raise Exception("Times is a different length than Links")
      
    d = {'Label':l,'Link':links,"Source":sources,"University":univs,"Department":depts,"Title"
    :titles,"Author":authors,"Date":dates,"Reference":refs,"Text":txts,"Time":times}
    df = pd.DataFrame(d)

    # drop unnamed row
    df.drop(df.filter(regex="Unname"),axis=1, inplace=True) 
    
    # write to txt file
    csv_data = df.to_csv('dataset.csv', index = True) 
     
    # initialize the log settings
    logging.basicConfig(filename='app.log',level=logging.INFO) 
    logfile = 'appfile.txt'
    filePointer = open(logfile,'r')
    try:
        content = filePointer.readline()
    finally:
          filePointer.close() 
    return df


  except (Exception) as e: 
    print(e)
    logging.exception(str(e))



print(build_output(l,links,sources,univs,depts,titles,authors,dates,refs,txts,times))

df = pd.read_csv('dataset.csv')

# when this code is used its dropped so it should be dropped in the csv?

# drop unnamed row
df.drop(df.filter(regex="Unname"),axis=1, inplace=True)

df.head()